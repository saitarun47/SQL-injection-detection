{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkexzQUurIQd",
        "outputId": "67f227d3-2405-410d-f7b6-bb77a4d44927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Est3wNifJGxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/sqli.csv\", encoding='utf-16')\n",
        "df = df.dropna()\n"
      ],
      "metadata": {
        "id": "aB3GC2xNJISn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['Sentence'].values\n",
        "y = df['Label'].values"
      ],
      "metadata": {
        "id": "0Wt-LYg5JIVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sql_query(query):\n",
        "    return query.split()"
      ],
      "metadata": {
        "id": "m2ev1bYFJIX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tokens = [tokenize_sql_query(query) for query in X]"
      ],
      "metadata": {
        "id": "veBs4AqaJIah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = Word2Vec(sentences=X_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "word2vec_model.save(\"word2vec_sqli.model\")\n"
      ],
      "metadata": {
        "id": "epDThBU9JIc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_average_word2vec(tokens_list, model, embedding_dim=100):\n",
        "    vectors = [model.wv[word] for word in tokens_list if word in model.wv]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(embedding_dim)  # Return zero vector if no word is in the model\n",
        "\n",
        "X_word2vec = np.array([get_average_word2vec(tokens, word2vec_model) for tokens in X_tokens])\n"
      ],
      "metadata": {
        "id": "TcQxPsVjJIfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weight_dict = dict(zip(np.unique(y), class_weights))\n"
      ],
      "metadata": {
        "id": "yh1CJ-1BJIhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.01)), input_shape=input_shape))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(96, return_sequences=True, kernel_regularizer=l2(0.01))))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.01))))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(128, kernel_regularizer=l2(0.01))))\n",
        "\n",
        "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=6.204036987017244e-05), metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "yAsv0qUpJIkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model((X_word2vec.shape[1], 1))\n",
        "history = model.fit(X_word2vec, y, epochs=50, batch_size=64,\n",
        "                    callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6),\n",
        "                               EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)],\n",
        "                    class_weight=class_weight_dict, verbose=1)\n"
      ],
      "metadata": {
        "id": "nu1HCvgrJIm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(X_word2vec)"
      ],
      "metadata": {
        "id": "cpgbAYmrJIqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n"
      ],
      "metadata": {
        "id": "di3jSu4EJlMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "j_scores = tpr - fpr\n",
        "optimal_threshold_index = np.argmax(j_scores)\n",
        "optimal_threshold = thresholds[optimal_threshold_index]\n",
        "print(f\"Optimal Threshold: {optimal_threshold}\")\n"
      ],
      "metadata": {
        "id": "3LrsX1nJJlIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (y_pred_prob > optimal_threshold).astype(int)"
      ],
      "metadata": {
        "id": "hYPIcwdgJptP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y, y_pred)\n",
        "print(f\"Classification Report:\\n{class_report}\")\n"
      ],
      "metadata": {
        "id": "L55qZKA4Jppy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('trained_lstm_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRmXiPUItwpi",
        "outputId": "41640e55-6e2a-406e-d567-e56cb656e1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iv7MXNHLzjLw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}